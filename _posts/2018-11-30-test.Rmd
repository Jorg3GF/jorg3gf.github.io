---
title: "Skyscrapers"
date: 2018-11-20
tags: [data cleaning]
output:
  html_document: default
excerpt: "Water collected on skyscrapers"
---

# PART 2

## Report

Now that we have loaded our data into Snowflake, we can use SQL queries to answer a few questions, such as:

1. How many issues were created in total?

*SELECT COUNT(DISTINCT key)
FROM issues;*

2. How many issues were created that we don't have historical records for?

*SELECT COUNT(DISTINCT key)
FROM (SELECT i.project, i.key, i.type, h.issue
  FROM history h
  RIGHT OUTER JOIN issues i ON i.key = h.issue)
WHERE issue IS NULL;*

3. What is the average Time to Close per project, since the moment tickets were first created? (assuming an issue is closed when its status gets Done)

*WITH new AS (
  SELECT i.project, h.issue, i.created AS created, h.created AS timepoints
  FROM history h
  INNER JOIN issues i ON i.key = h.issue
  WHERE i.status in ('Done')),
range AS (SELECT project, issue, MIN(created) created, MAX(timepoints) timepoints FROM new GROUP BY project,issue),
diff AS (SELECT project, issue, DATEDIFF(day, range.created, range.timepoints) days FROM range)*

*SELECT project, ROUND(AVG(days),0) Days_to_complete
FROM diff
GROUP BY project;*

***

But I'd rather keep investigating the datasets in R, due to its flexibility and data visualization capabilities.
```{R warning = FALSE, message = FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(RColorBrewer)
library(treemapify)
issues <- read.csv("~/Desktop/issues.csv")
history <- read.csv("~/Desktop/history.csv")
issues$Created <- as.POSIXct(issues$Created, format = "%Y-%m-%d %H:%M", tz="GMT")
history$Created <- as.POSIXct(history$Created, format = "%Y-%m-%d %H:%M", tz="GMT")
```

In total, there are `r nrow(issues)` issues created between `r min(issues$Created)` and `r max(issues$Created)`, which are distributed across **projects** and **types** the following way:

```{R warning = FALSE, message = FALSE, echo = FALSE, fig.align = "center"}
proj_type <- issues %>% group_by(Project, Type) %>% summarise(tickets = n())
ggplot(proj_type, aes(area = tickets, fill = Type, label=Type, subgroup=Project)) +
  geom_treemap(aes(alpha = tickets)) +
  geom_treemap_subgroup_border(colour="white") +
  geom_treemap_text(fontface = "italic",
                    colour = "white",
                    place = "centre",
                    grow = F,
                    reflow=T) +
  geom_treemap_subgroup_text(place = "centre",
                             grow = T,
                             alpha = 0.5,
                             colour = "#FAFAFA",
                             min.size = 0) +
  scale_alpha_continuous(range = c(0.2, 1)) + ggtitle("Number of Tickets by Type for each Project") + theme(legend.position = "none")
```
```{R warning = FALSE, message = FALSE, results='asis', echo=F}
library(knitr)
library(kableExtra)
kable(as.data.frame(spread(proj_type,Project,tickets)) %>% replace(is.na(.), 0)) %>% kable_styling(bootstrap_options = c("striped","condensed","hover"), full_width = F) %>% add_header_above(c("Total Number of Issues" = 6))
```

*DW* and *TAL* are the projects which created the largest amount of issues.
*Bugs* and *Stories* are the most popular types. **Types** of issues seem to follow a similar trend across different **projects**, as suggested in the table above (also represented in the chart below):

```{R warning = FALSE, message = FALSE, fig.align = "center", echo=F, fig.width=5, fig.height=4}
pt_prop <- as.data.frame(table(issues$Type,issues$Project) %>% prop.table(margin = 2) %>% round(2))
colnames(pt_prop)[1] <- paste("Type")
colnames(pt_prop)[2] <- paste("Project")
colnames(pt_prop)[3] <- paste("Prop")
ggplot(data=pt_prop, aes(x=Project, y=Prop, fill=Type)) +
  geom_bar(stat="identity")+
  ggtitle("Evolution of Tickets Creation by Project and Type")+
  scale_fill_brewer(palette="Paired") + ylab("Share") + coord_flip() + scale_y_continuous(labels = scales::percent)
```

Despite the similar distribution of **types** of issues across **projects**, is important to highlight the fact that *DFO* is the one with the largest share of *bugs*.

But how have issues evolved overtime?

```{R warning = FALSE, message = FALSE, fig.align = "center", echo=F}
issues$month <- format(as.Date(issues$Created), "%Y-%m")
i_overtime <- issues %>% group_by(month) %>% summarise(tickets = n())
ggplot(i_overtime, aes(x=month, y=tickets, group = 1)) +
  geom_line(color="#ff2400") +
  xlab("Month") +
  theme(axis.text.x  = element_text(angle=90, vjust=1)) +
  ggtitle("Tickets Created Overtime")
```

In July 2018 the volume of tickets created plunged because we only have records until `r max(issues$Created)`. Would be great to break down this growth in order to better understand its roots.

```{R warning = FALSE, message = FALSE, echo = FALSE, fig.align = "center"}
issues_proj <- issues %>% group_by(month, Project) %>% summarise(tickets = n())
ggplot(data=issues_proj, aes(x=month, y=tickets, fill=Project)) +
  geom_bar(stat="identity")+
  theme(axis.text.x  = element_text(angle=90, vjust=1)) +
  ggtitle("Evolution of Tickets Creation by Project")+
  scale_fill_brewer(palette="Spectral")
```

From May 2017, the volume of tickets increased due to *DW*. In October 2017, *GTM* massively contributed to tickets volume and, from November 2017, it increases further due to both *CVAL* and *DFO*. But it is because of these two **projects** that we see a sudden drop in April 2018. Also, *TAL* gets particularly representative in January and May 2018.

In terms of **types** of tickets, evolution goes the following way.

```{R warning = FALSE, message = FALSE, echo = FALSE, fig.align = "center"}
issues_type <- issues %>% group_by(month, Type) %>% summarise(tickets = n())
ggplot(data=issues_type, aes(x=month, y=tickets, fill=Type)) +
  geom_bar(stat="identity")+
  theme(axis.text.x  = element_text(angle=90, vjust=1)) +
  ggtitle("Evolution of Tickets Creation by Type")+
  scale_fill_brewer(palette="Paired")
```

*Bugs* and *Stories* are the most popular types of tickets, but *Sub-Tasks* have consistently gained ground recently. Further details in [attachments](#attachment0).

<a id="back4"></a>

And how are tickets creation spread in a month? And in a week? What about in a day?

```{R warning = FALSE, message = FALSE, out.width=c('50%', '50%'), fig.show='hold', echo = F}
issues$day <- format(as.Date(issues$Created), "%d")
issues_day <- issues %>% group_by(day) %>% summarise(tickets = n())
ggplot(data=issues_day, aes(x=day, y=tickets, group=1)) +
  geom_line(stat="identity", color="#ff2400")+
  theme(axis.text.x  = element_text(angle=90, vjust=1)) +
  ggtitle("Evolution of Tickets Creation by Day on Month") + xlab("Day of Month")
issues$day_of_week <- weekdays(issues$Created)
issues_dow <- issues %>% group_by(day_of_week) %>% summarise(tickets = n())
issues_dow$day_of_week <- factor(issues_dow$day_of_week, levels= c("Sunday", "Monday",
                                         "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
issues_dow <- issues_dow[order(issues_dow$day_of_week), ]
ggplot(data=issues_dow, aes(x=day_of_week, y=tickets, group=1)) +
  geom_bar(stat="identity", fill="#ff2400")+
  ggtitle("Evolution of Tickets Creation by Day on Week") + xlab("Day of Week")
```
```{R warning = FALSE, message = FALSE, echo=F, fig.align = "center", fig.width=5, fig.height=4}
issues$hour <- strftime(issues$Created, format="%H")
issues_hour <- issues %>% group_by(hour) %>% summarise(tickets = n())
ggplot(data=issues_hour, aes(x=hour, y=tickets, group=1)) +
  geom_line(stat="identity", color="#ff2400")+
  ggtitle("Evolution of Tickets Creation by Hour") + xlab("Hour")
```

I believe there's nothing wrong with the time tickets are created, they follow a fair distribution in a month, week or day.

If we take a closer look at the *history* and *issues* files, we realize we lack historical data for `r nrow(filter(issues, !(Key %in% history$Issue)))` tickets. See further analysis in [attachments](#attachments).
<a id="back"></a>
But let's focus our investigation on tickets which have historical data. So, let's merge both datasets in order to go deeper in tickets' dynamics.
```{R warning = FALSE, message = FALSE, echo=F}
names(issues)[2] <- paste("Issue")
names(issues)[3] <- paste("First Created")
hi <- inner_join(history, issues, by="Issue")
hi <- select(hi, Project, Issue, `Type.y`, Status, Author, `First Created`, Created, From, From.String, To, To.String)
names(hi)[3] <- paste("Type")
```

From all `r length(unique(issues$Issue))` issues created, we only have historical data for `r length(unique(hi$Issue))` and only `r nrow(issues[issues$Status=="Done",])` issues were completed/done.
Each ticket follows a specific path to get done, going through different stages and authors, taking different timings. We can get a summary of these metrics by ticket the following way:
```{R warning = FALSE, message = FALSE}
hi_resume <- hi %>%
  group_by(Project,Issue,Type,Status) %>%
  summarise(requested = min(`First Created`), kickoff = min(Created), delivered = max(Created), status_changes=n(), nr_authors = n_distinct(Author)) %>%
  mutate(time2kick = as.numeric(round(difftime(kickoff,requested,units="days"),0)), leadtime = as.numeric(round(difftime(delivered,kickoff,units="days"),0)), totaltime = as.numeric(round(difftime(delivered,requested,units="days"),0))) %>% as.data.frame
head(hi_resume)
```

In my perspective, time can be divided into 3 distinct stages:
1. **Requested** when the issue was first created in the platform;
2. **Kick Off** when the first stage of the process was completed and the ticket moved to the next one;
3. **Delivered** when it reached the last stage in our records, either completed or not.

Therefore, we can come up with 3 metrics:
1. **Time2kick** tells us two things at once: how long the issue waited in the line until it was first picked up by the first stage, plus how long the first stage took to complete;
2. **Lead time** which represents the time it took from the second stage until it reached the last stage in our records;
3. **Total time** which is the sum of the previous two stages, or the time it took since it was created in the platform until it reached the last stage in our records.

We can also get the number of **status changes** each ticket went through, as well as the number of distinct people who owned them (**nr_authors**).

From here, we can develop a lot of different views for our data. I am curious about how these new variables correlate with each other...
```{R warning = FALSE, message = FALSE, fig.align = "center", fig.width=4, fig.height=4, echo=F}
library("GGally")
ggcorr(hi_resume[,8:12], nbreaks=8, palette='RdGy', label=TRUE, label_size=5, label_color='white')
```
Of course **total time** is highly correlated with both **lead time** and **time2kick**. Also, **status changes** with **nr_authors** is expectable, as the more stages issues go through, the more distinct people are likely to be involved.
However, I was surprised to see that **status_changes** and **nr_authors** don't correlate at all with any of the time variables. Furthermore, I was also expecting to see some kind of correlation between **time2kick** and **leadtime**, as per haps the more time consuming issues are, the quicker they would be picked up. But our data doesn't confirm this relationship.

How are these variables distributed? For example, how does time behave?

```{R warning = FALSE, message = FALSE, fig.align = "center", fig.width=4, fig.height=3, echo=F}
ggplot(hi_resume, aes(x="", y=totaltime)) +
  geom_boxplot(fill="#ff2400") + ylab("Days") +
  coord_cartesian(ylim=c(0, 100)) + ggtitle("Total time distribution for issues") + theme(axis.title.x=element_blank())
```

Overall, 50% of issues take around three weeks to reach to their last stage (either completed or not).
What happens to time variables across **Projects**? (there are plenty of outliers in our dataset and the maximum value for **total time** is `r max(hi_resume$totaltime)` days, but I will establish shorter y limits for the sake off better viz).

```{R warning = FALSE, message = FALSE, out.width=c('50%', '50%'), fig.show='hold', echo = F}
ggplot(hi_resume, aes(x=Project, y=time2kick)) +
  geom_boxplot(fill="salmon", alpha=0.2) + ylab("Days") +
  xlab("Project") + coord_cartesian(ylim=c(0, 100)) + ggtitle("Time to kickoff distribution of issues across Projects") + theme(axis.title.x=element_blank())
ggplot(hi_resume, aes(x=Project, y=leadtime)) +
  geom_boxplot(fill="darkseagreen2", alpha=0.2) + ylab("Days") +
  xlab("Project") + coord_cartesian(ylim=c(0, 100)) + ggtitle("Lead time distribution of issues across Projects") + theme(axis.title.x=element_blank())
```

It looks like time doesn't vary that much across **Projects**. Below there's a summary table for each one of the variables above, by project. I used medians as a measure to compare projects, so we can avoid the outliers effect.

```{R warning = FALSE, message = FALSE, results='asis', echo=F}
library(kableExtra)
proj_resume <- hi_resume %>% group_by(Project) %>% summarise(status_changes=median(status_changes), nr_authors=median(nr_authors), time2kick=median(time2kick),leadtime=median(leadtime), totaltime=median(totaltime))
kable(proj_resume) %>% kable_styling(bootstrap_options = c("striped","condensed","hover"), full_width = F)
```

*DFO* and *GTM* are the projects where issues are taken care more quickly. It is impressive how *time2kick* weights so much over *totaltime* for *CVAL* and *TAL*.  It means that either these projects take so long to pick issues up, or their first stage is very time consuming.
One hypothesis is that it might depend on the **types** of issues they usually deal with. We will further investigate their relationship in a while, but before that, I want to execute the same view for types of issues only.

```{R warning = FALSE, message = FALSE, out.width=c('50%', '50%'), fig.show='hold', echo = F}
ggplot(hi_resume, aes(x=Type, y=time2kick)) + geom_boxplot(fill="salmon", alpha=0.2) + theme(axis.text.x  = element_text(angle=90, vjust=1), axis.title.x=element_blank()) + coord_cartesian(ylim=c(0, 300)) + ggtitle("Time to kickoff distribution across types of issues") + ylab("Days")

ggplot(hi_resume, aes(x=Type, y=leadtime)) + geom_boxplot(fill="darkseagreen2", alpha=0.2) + theme(axis.text.x  = element_text(angle=90, vjust=1), axis.title.x=element_blank()) + ggtitle("Lead time distribution across types of issues") + ylab("Days") + coord_cartesian(ylim=c(0, 300))
```
```{R warning = FALSE, message = FALSE, results='asis', echo=F}
issues_resume <- hi_resume %>% group_by(Type) %>% summarise(status_changes=median(status_changes), nr_authors=median(nr_authors), time2kick=median(time2kick),leadtime=median(leadtime), totaltime=median(totaltime))
kable(issues_resume) %>% kable_styling(bootstrap_options = c("striped","hover","condensed"), full_width = F)
```

*Epic*, *Idea* and *Initiative* issues show a lot of variability and much higher **total time**, when compared to other **types** such as *Bugs* or even *Questions*. A plausible reason for this situation is the fact that these types of tickets are more complex and time consuming to implement, than fixing bugs, for example.

But how do **types** of issues relate with **projects**?

```{R warning = FALSE, message = FALSE, fig.align = "center", echo=F}
ggplot(hi_resume, aes(x=Project, y=totaltime)) +
  geom_boxplot(fill="#ff2400", position = 'identity') +
  ylab("Days") + facet_grid(~Type) + facet_wrap(~Type, ncol=3) +
  ggtitle("Total time taken by Project and Type of issues") + coord_cartesian(ylim=c(0, 400)) + theme(axis.title.x=element_blank())
```

Here we can see one of the reasons why *DFO* and *GTM* see their issues being solved quicker than remaing projects: the types of issues which take a long time are not created under *DFO* and *GTM*.
*Bugs*, *stories* and *sub-tasks* take approximately the same time to be solved across **projects**.
*Research* in *CVAL* and *Epics* in *TAL* take forever...

Meanwhile, another question comes up: what about the difference between tickets which were solved by the time of this extraction and the ones which are still pending?
Firstly, a quick look at volumes... (further details [here](#here))
```{R warning = FALSE, message = FALSE, fig.align = "center", echo=F}
hi_resume$done <- ifelse(hi_resume$Status=="Done", "Yes", "No")
volumes <- as.data.frame(table(hi_resume$Project,hi_resume$done, hi_resume$Type))
colnames(volumes)[1] <- paste("Project")
colnames(volumes)[2] <- paste("Solved")
colnames(volumes)[3] <- paste("Type")
colnames(volumes)[4] <- paste("Issues")
ggplot(volumes, aes(x = Project, y = Issues, fill = Solved)) +
  geom_bar(stat = "identity") + facet_grid(~Type) + facet_wrap(~Type, ncol=3) + ggtitle("Number of Issues by Project and Type: Solved vs Unsolved") + scale_fill_manual(values=c("grey40", "#ff2400"))
```

<a id="back2"></a>
More than half of *DFOs' stories* haven't been solved yet. *Sub-tasks* (including *Bugs* and *Technical*) are extraordinarily successful in their completion.

I think would be valuable to perform a similar analysis for our metrics, taking into consideration the issues which were solved and the ones still to be completed.
```{R warning = FALSE, message = FALSE, fig.align = "center", echo=F, fig.height=3,}
ggplot(hi_resume, aes(x=done, y=time2kick, group=done)) +
  geom_boxplot(aes(fill=done)) +
  xlab("Solved?") + facet_grid(~Project) + ylab("Days") + coord_cartesian(ylim=c(0, 300)) + ggtitle("Time taken to kick off issues by Project for Solved vs Unsolved Issues") + theme(legend.position = "none") + scale_fill_manual(values=c("grey40", "#ff2400"))
ggplot(hi_resume, aes(x=done, y=leadtime, group=done)) +
  geom_boxplot(aes(fill=done)) +
  xlab("Solved?") + facet_grid(~Project) + ylab("Days") + coord_cartesian(ylim=c(0, 300)) + ggtitle("Lead time taken by Project for Solved vs Unsolved Issues") + theme(legend.position = "none") + scale_fill_manual(values=c("grey40", "#ff2400"))
ggplot(hi_resume, aes(x=done, y=totaltime, group=done)) +
  geom_boxplot(aes(fill=done)) +
  xlab("Solved?") + facet_grid(~Project) + ylab("Days") + coord_cartesian(ylim=c(0, 300)) + ggtitle("Total time taken by Project for Solved vs Unsolved Issues") + theme(legend.position = "none") + scale_fill_manual(values=c("grey40", "#ff2400"))
```

This tells us that the quicker issues are picked up, their chance of being solved is higher than the ones which remain in standby for a long time. Time to kick off highly affects issues' delivery. In fact, lead time doesn't seem to be excessively high.
Issues for *CVAL* and *TAL* projects take too long to be picked up. They deal with *Epics* and *Ideas* more than their counterparts, but that shouldn't be the only reason, as volumes of these types are low. The trend also happens for *Stories*, for example, where these **projects** take some time to start off:
```{R warning = FALSE, message = FALSE, results='asis', echo=F}
kable(filter(hi_resume,Type=="Story") %>% group_by(Project) %>% summarise(time2kick=median(time2kick))) %>% kable_styling(bootstrap_options = c("striped","condensed","hover"), full_width = F) %>% footnote(general = "Data for Stories only.")
```
*CVAL* and *TAL* take a median of 6 to 9 days to kick off *Stories*, respectively.

What about the distribution of *time to kick off* by type? How does it look like?

```{R warning = FALSE, message = FALSE, fig.align = "center", echo=F}
ggplot(hi_resume, aes(x=done, y=time2kick, group=done)) +
  geom_boxplot(aes(fill=done)) +
  xlab("Solved?") + facet_grid(~Type) + facet_wrap(~Type, ncol=3) + ylab("Days") + coord_cartesian(ylim=c(0, 300)) + ggtitle("Time taken to kick off issues by Type for Solved vs Unsolved Issues") + scale_fill_manual(values=c("grey40", "#ff2400"))
```

Again, to confirm my previous statement, the longer issues take to kick off, the less chances they have to get completed. *Initiatives*, for example, never got done! Conversely, *Technical Sub-Tasks* were all completed.

Therefore, I believe that the *kick off* moment is extraordinarily important in predicting whether issues will be solved and how fast this will happen. So, it is key to deep dive into the first stage of the process.

```{R warning = FALSE, message = FALSE, echo=F, fig.align = "center", fig.width=5, fig.height=2}
hi_resume_from <- hi %>%
  group_by(Project, Issue, Type, Status) %>%
  slice(n())
from <- as.data.frame(table(hi_resume_from$From.String))
colnames(from)[1] <- paste("from_string")
colnames(from)[2] <- paste("Issues")
from$Issues[from$Issues<10] <- NA
from <- na.omit(from)
ggplot(data=from, aes(x=from_string, y=Issues)) +
  geom_bar(stat="identity", fill="#ff2400")+
  ggtitle("Number of tickets by first stage")+ xlab("First Stage") +
  scale_fill_brewer(palette="Paired") + ylab("Issues") + coord_flip()
```

Typically, the first stages of the process are *To Do* and *Screen Issue*. There are a few issues which start off with different stages, but for the purpose of our analysis, we can ignore these exceptions and focus on these two. In fact, `r round(nrow(hi_resume_from[hi_resume_from$From.String=="To Do" | hi_resume_from$From.String=="Screen Issue",])/nrow(hi_resume)*100,2)`% of total issues start either on *To Do* or *Screen Issue*.

```{R warning = FALSE, message = FALSE, echo=F, fig.align = "center", fig.width=5, fig.height=2}
hi_resume_from2 <- hi_resume_from %>% mutate(time_diff = round(difftime(Created, `First Created`, units="days"),0))
hi_resume_from2$done <- ifelse(hi_resume_from2$Status=="Done","Yes","No")
from_done <- as.data.frame(table(hi_resume_from2$From.String,hi_resume_from2$done) %>% prop.table(margin = 1) %>% round(3))
colnames(from_done)[1] <- paste("from_string")
colnames(from_done)[2] <- paste("done")
colnames(from_done)[3] <- paste("Issues")
from_done$from_string[from_done$from_string!="To Do"&from_done$from_string!="Screen Issue"] <- NA
from_done <- na.omit(from_done)
ggplot(data=from_done, aes(x=from_string, y=Issues, fill=done)) +
  geom_bar(stat="identity")+
  ggtitle("First Stage: Solved vs Not Solved")+ xlab("First Stage") +
  ylab("Share") + coord_flip() + scale_y_continuous(labels = scales::percent) + scale_fill_manual(values=c("grey40", "#ff2400"))
```

More than half of issues which start at *Screen Issue* don't get done.
Overall, how long does this step usually take?

```{R warning = FALSE, message = FALSE, echo=F, fig.align = "center", results='asis'}
lag <- hi_resume_from2 %>% group_by(From.String) %>% summarise(time = median(time_diff)) %>% filter(From.String=="Screen Issue" | From.String=="To Do")
kable(lag) %>% kable_styling(bootstrap_options = c("striped","condensed","hover"), full_width = F)
```

When an issue starts with *To Do*, it usually takes 2 days to pass onto the next stage, whereas when it starts with a *Screen* it takes around 35 days. The difference gets even larger if we consider the issues which are successfully completed.

```{R warning = FALSE, message = FALSE, echo=F, fig.align = "center", results='asis'}
kable(hi_resume_from2 %>% group_by(From.String, done) %>% summarise(time = median(time_diff)) %>% spread(done, time) %>% filter(From.String=="Screen Issue" | From.String=="To Do")) %>% kable_styling(bootstrap_options = c("striped","condensed","hover"), full_width = F) %>% add_header_above(c(" " = 1, "Solved?" = 2))
```

The **Projects** which are most affected by this delay are *DW*, *CVAL* and *TAL*.

```{R warning = FALSE, message = FALSE, echo=F, fig.align = "center", fig.width=5, fig.height=2}
screen_issue <- hi_resume_from[hi_resume_from$From.String=="Screen Issue",]
si_proj <- as.data.frame(prop.table(table(screen_issue$Project)) %>% round(2))
colnames(si_proj)[1] <- paste("Project")
colnames(si_proj)[2] <- paste("Issues")
ggplot(data=si_proj, aes(x="", y=Issues, fill=Project)) +
  geom_bar(stat="identity")+
  ggtitle("Tickets Creation for Screen Issue, by Project")+
  scale_fill_brewer(palette="RdGy") + ylab("Share") + coord_flip() + scale_y_continuous(labels = scales::percent) +theme(axis.title.y=element_blank())
```

The **Types** of issues which are most affected by *screen issue's* delay are *Bugs* and *Stories*.
```{R warning = FALSE, message = FALSE, echo=F, fig.align = "center", fig.width=5, fig.height=3}
si_type <- as.data.frame(prop.table(table(screen_issue$Type)) %>% round(2))
colnames(si_type)[1] <- paste("Type")
colnames(si_type)[2] <- paste("Issues")
ggplot(data=si_type, aes(x="", y=Issues, fill=Type)) +
  geom_bar(stat="identity")+
  ggtitle("Tickets Creation for Screen Issue, by Type")+
  scale_fill_brewer(palette="RdGy") + ylab("Share") + coord_flip() + scale_y_continuous(labels = scales::percent) +theme(axis.title.y=element_blank()) + theme(legend.position="bottom")
```
Further details [here](#here2)

<a id="back3"></a>


***



<style>
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>
<div class = "blue">

### Final Thoughts

- Issues' first stage in the process is a key moment - it highly affects total time of tickets' completion. The quicker they are picked up, the higher the chances they will be solved whithin a reasonable timeframe;
- The Screen Issue stage is the bottleneck. It is the stage where tickets take the longest time to progress, when compared to remaining first stages. I would recommend assigning more collaborators to this step;
- Alternatively, the process can be redesigned or develop a system to attribute levels of priorities, so important *bugs* and *stories* are addressed as quick as possible;
- *Epics*, *Ideas* and *Initiatives* take much longer to develop than remaining types of issues. I would suggest allocating a task force to these issues, in order to speed up their implementation, as interesting and innovative actions might come up from there.
- A task force could also be created to clean issues' pipeline. There are tickets which were created a long time ago and have been on standby for ages. Probably, subjects discussed in these issues were raised again with different IDs and got duplicated.

</div>





***




<a id="attachment0"></a>

##Attachments

### Evolution of Tickets creation by Type and Project
```{R warning = FALSE, message = FALSE, echo = FALSE, fig.align = "center", fig.width=9, fig.height=6}
issues_pt <- issues %>% group_by(month, Project, Type) %>% summarise(tickets = n())
ggplot(data=issues_pt, aes(x=month, y=tickets, fill=Type)) +
  geom_bar(stat="identity")+
  theme(axis.text.x  = element_text(angle=90, vjust=1, size=5)) +
  ggtitle("Evolution of Tickets Creation by Project")+
  scale_fill_brewer(palette="Spectral")+facet_grid(~Project)+facet_wrap(~Project)
```
[Back](#back4)

<a id="attachments"></a>

###Missing Historical Data

Below, we see the number of tickets by type and project where historical data is missing:
```{R warning = FALSE, message = FALSE, out.width=c('50%', '50%'), fig.show='hold', echo = F}
no_hist <- subset(issues, !(Issue %in% history$Issue))
no_hist_proj <- no_hist %>% group_by(month, Project) %>% summarise(tickets = n())
ggplot(data=no_hist_proj, aes(x=month, y=tickets, fill=Project)) +
  geom_bar(stat="identity")+
  theme(axis.text.x  = element_text(angle=90, vjust=1)) +
  ggtitle("Evolution of Tickets w/o History by Project")+
  scale_fill_brewer(palette="Spectral")
no_hist_type <- no_hist %>% group_by(month, Type) %>% summarise(tickets = n())
ggplot(data=no_hist_type, aes(x=month, y=tickets, fill=Type)) +
  geom_bar(stat="identity")+
  theme(axis.text.x  = element_text(angle=90, vjust=1)) +
  ggtitle("Evolution of Tickets w/o History by Type")+
  scale_fill_brewer(palette="Paired")
```
Historical data is missing across all **projects** and **types** of issues, except for *Bug-Sub-Tasks* and *Technical Sub-Tasks*.
However, **status** are not distributed the same way...
```{R warning = FALSE, message = FALSE, echo=F, fig.align = "center", fig.width=5, fig.height=3}
h <- as.data.frame(prop.table(table(issues$Status)))
colnames(h)[1] <- paste("Status")
colnames(h)[2] <- paste("Issues")
h <- h[order(h$Issues, decreasing = T),]
ggplot(data=h[1:12,], aes(x="", y=Issues, fill=Status)) +
  geom_bar(stat="identity")+
  ggtitle("Total Issues Created by Status")+
  scale_fill_brewer(palette="Set3") + ylab("Share") + coord_flip() + scale_y_continuous(labels = scales::percent) +theme(axis.title.y=element_blank()) + theme(legend.position="bottom")
t <- as.data.frame(prop.table(table(no_hist$Status)))
colnames(t)[1] <- paste("Status")
colnames(t)[2] <- paste("Issues")
t <- t[order(t$Issues, decreasing = T),]
t[t$Issues==0,] <- NA
t <- na.omit(t)
ggplot(data=t, aes(x="", y=Issues, fill=Status)) +
  geom_bar(stat="identity")+
  ggtitle("Issues without Historical Data by Status")+
  scale_fill_brewer(palette="Accent") + ylab("Share") + coord_flip() + scale_y_continuous(labels = scales::percent) +theme(axis.title.y=element_blank()) + theme(legend.position="bottom")
```
Interestingly, from all `r nrow(issues[issues$Status=="Done",])` issues completed, we don't have historical data for only `r nrow(subset(issues[issues$Status=="Done",], !(Issue %in% hi[hi$Status=="Done",]$Issue)))` of them:
```{R warning = FALSE, message = FALSE}
subset(issues[issues$Status=="Done",], !(Issue %in% hi[hi$Status=="Done",]$Issue))
```
[Back](#back)

<a id="here"></a>

###Issues solved, by *Project* and *Type*
```{R warning = FALSE, message = FALSE, echo=F, fig.align = "center", results='asis'}
hi_resume_done <- hi_resume[hi_resume$done=="Yes",]
kable(table(hi_resume_done$Type,hi_resume_done$Project)) %>% kable_styling(bootstrap_options = c("striped","condensed","hover"), full_width = F) %>% add_header_above(c("Number of Solved Issues" = 6))
PTdone <- as.data.frame(round(table(hi_resume_done$Type,hi_resume_done$Project)/table(hi_resume$Type,hi_resume$Project),2))
PTdone[is.na(PTdone)] <- 0
colnames(PTdone)[1] <- paste("Type")
colnames(PTdone)[2] <- paste("Project")
colnames(PTdone)[3] <- paste("%Solved")
kable(PTdone %>% spread(Project, `%Solved`)) %>% kable_styling(bootstrap_options = c("striped","condensed","hover"), full_width = F) %>% add_header_above(c("Share of Solved Issues" = 6))
```
```{R warning = FALSE, message = FALSE, fig.align = "center", echo=F}
hi_resume_done_stats <- hi_resume_done %>%
  group_by(Project,Type) %>%
  summarise(status_changes=median(status_changes),nr_authors=median(nr_authors),time2kick=median(time2kick),leadtime=median(leadtime),totaltime=median(totaltime))
t2kPTdone <- select(hi_resume_done_stats,Project,Type,time2kick) %>% spread(Project,time2kick)
ltPTdone <- select(hi_resume_done_stats,Project,Type,leadtime) %>% spread(Project,leadtime)

ggplot(hi_resume_done, aes(x=Project, y=time2kick)) +
  geom_boxplot(fill="#ff2400", position = 'identity') +
  ylab("Days") + facet_grid(~Type) + facet_wrap(~Type, ncol=3) +
  ggtitle("Time2Kick by Project and Type for solved issues") + coord_cartesian(ylim=c(0, 400)) + theme(axis.title.x=element_blank())
t2kPTdone[is.na(t2kPTdone)] <- 0
kable(t2kPTdone) %>% kable_styling(bootstrap_options = c("striped","condensed","hover"), full_width = F) %>% add_header_above(c("Median of Time2Kick for Solved Issues" = 6))

ggplot(hi_resume_done, aes(x=Project, y=leadtime)) +
  geom_boxplot(fill="#ff2400", position = 'identity') +
  ylab("Days") + facet_grid(~Type) + facet_wrap(~Type, ncol=3) +
  ggtitle("Lead Time by Project and Type for solved issues") + coord_cartesian(ylim=c(0, 400)) + theme(axis.title.x=element_blank())
ltPTdone[is.na(ltPTdone)] <- 0
kable(ltPTdone) %>% kable_styling(bootstrap_options = c("striped","condensed","hover"), full_width = F) %>% add_header_above(c("Median of Lead Time for Solved Issues" = 6))
```
[Back](#back2)

<a id="here2"></a>

###Issues solved vs not solved when *Screen Issue* as first stage

```{R warning = FALSE, message = FALSE, echo=F, fig.align = "center", results='asis'}
screen_done <- screen_issue[screen_issue$Status=="Done",]
table_si <- round(table(screen_done$Type,screen_done$Project)/table(screen_issue$Type,screen_issue$Project),2)
table_si[is.na(table_si)] <- 0
kable(table_si) %>% kable_styling(bootstrap_options = c("striped","condensed","hover"), full_width = F) %>% add_header_above(c("% of Solved Issues by Project & Type" = 6))
```
[Back](#back3)
